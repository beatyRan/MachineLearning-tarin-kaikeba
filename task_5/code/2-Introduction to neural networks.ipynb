{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building deep learning models with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-16bc85d8578a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 读取数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_wages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/hourly_wages.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# 特征数量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mn_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_wages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/python/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/python/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/python/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/python/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/python/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data/hourly_wages.csv does not exist: './data/hourly_wages.csv'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./data/hourly_wages.csv does not exist: './data/hourly_wages.csv'",
     "output_type": "error"
    }
   ],
   "source": [
    "# 导入模块\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "\n",
    "# 读取数据集\n",
    "df_wages = pd.read_csv('./data/hourly_wages.csv')\n",
    "# 特征数量\n",
    "n_cols = df_wages.iloc[:, 1:].shape[1]\n",
    "\n",
    "# 构建模型\n",
    "model = Sequential()\n",
    "# 增加第一个隐层\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "# 增加第二个隐层\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# 增加输出层\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_wages.head()\n",
    "n_cols\n",
    "df_wages.shape\n",
    "df_wages.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling and fitting a model\n",
    "https://keras.io/optimizers/#adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(df_wages.iloc[:, 1:], df_wages.iloc[:, 0], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.epoch, history.history['loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.predict(df_wages.iloc[0:5, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('./resource/titanic_all_numeric.csv')\n",
    "X_train_titanic = df_titanic.drop(['survived'], axis=1)\n",
    "n_cols = X_train_titanic.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_titanic.head()\n",
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 模块导入\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 生成标签\n",
    "y_train_titanic = to_categorical(df_titanic.survived)\n",
    "\n",
    "# 建模\n",
    "model = Sequential()\n",
    "# 单隐层\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "# 输出层\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# Compile\n",
    "model.compile(optimizer='sgd', loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train_titanic, y_train_titanic, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_train_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(model.history.epoch, model.history.history['accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using models\n",
    "\n",
    "**Saving, reloading and using your Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "model.save('./models/model_file.h5')\n",
    "\n",
    "my_model = load_model('./models/model_file.h5')\n",
    "predictions = my_model.predict(X_train_titanic)\n",
    "probability_true = predictions[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "predictions\n",
    "probability_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pred_classes = np.argmax(predictions,axis=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "accuracy = metrics.accuracy_score(y_pred=pred_classes,y_true=df_titanic.survived)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# loss,accuracy\n",
    "score = model.evaluate(X_train_titanic, y_train_titanic, verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_new_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lr_to_test = [.000001, 0.01, 1]\n",
    "\n",
    "# loop over learning rates\n",
    "input_shape = (n_cols,)\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    model = get_new_model(input_shape)\n",
    "    my_optimizer = keras.optimizers.SGD(lr=lr)\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
    "    model.fit(X_train_titanic, y_train_titanic, epochs=10)\n",
    "    print('\\n' + '=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model = get_new_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_titanic, y_train_titanic, validation_split=0.3, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = get_new_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_titanic, y_train_titanic, validation_split=0.3, epochs=50,\n",
    "          callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More experimentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_1 = get_new_model(input_shape)\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(30, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu')) \n",
    "model_2.add(Dense(30, activation='relu')) \n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(X_train_titanic, y_train_titanic, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(X_train_titanic, y_train_titanic, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=0)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "### PyTorch compared to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 3, 5],\n        [1, 2, 9]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    },
    {
     "data": {
      "text/plain": "array([[2, 3, 5],\n       [1, 2, 9]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "torch.tensor([[2, 3, 5], [1, 2, 9]])\n",
    "\n",
    "np.array([[2, 3, 5], [1, 2, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8948, 0.1103],\n        [0.9110, 0.8475]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    },
    {
     "data": {
      "text/plain": "array([[0.19089095, 0.68994118],\n       [0.31879831, 0.02630596]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "torch.rand(2, 2)\n",
    "\n",
    "np.random.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 5])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    },
    {
     "data": {
      "text/plain": "(3, 5)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "a = torch.rand((3, 5))\n",
    "a.size()\n",
    "\n",
    "a = np.random.rand(3, 5) \n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix operations\n",
    "**PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2021, 0.3002],\n        [0.6086, 0.2630]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    },
    {
     "data": {
      "text/plain": "tensor([[0.4071, 0.4041],\n        [0.8681, 0.9787]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "a = torch.rand(2, 2) \n",
    "b = torch.rand(2, 2)\n",
    "a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "torch.matmul(a, b)\n",
    "\n",
    "a[0, 0] * b[0, 0] + a[0, 1] * b[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "a * b\n",
    "\n",
    "a[0, 0] * b[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.76774303, 0.12673361],\n       [0.9809297 , 0.60655661]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    },
    {
     "data": {
      "text/plain": "array([[0.96938192, 0.60063558],\n       [0.06316672, 0.61934459]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "a = np.random.rand(2, 2) \n",
    "b = np.random.rand(2, 2)\n",
    "a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.dot(a, b)\n",
    "\n",
    "a[0, 0] * b[0, 0] + a[0, 1] * b[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.multiply(a, b)\n",
    "\n",
    "a[0, 0] * b[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and Ones\n",
    "**PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "a_torch = torch.zeros(2, 2)\n",
    "a_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "b_torch = torch.ones(2, 2)\n",
    "b_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "c_torch = torch.eye(2)\n",
    "c_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "a_numpy = np.zeros((2, 2))\n",
    "a_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "b_numpy = np.ones((2, 2))\n",
    "b_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "c_numpy = np.identity(2)\n",
    "c_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch to NumPy and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "torch.from_numpy(c_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "c_torch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create a matrix of ones with shape 3 by 3\n",
    "tensor_of_ones = torch.ones(3, 3)\n",
    "\n",
    "# Create an identity matrix with shape 3 by 3\n",
    "identity_tensor = torch.eye(3)\n",
    "\n",
    "# Do a matrix mulitplication of tensor_of_ones with identity_tensor\n",
    "matrices_multiplied = torch.matmul(tensor_of_ones, identity_tensor)\n",
    "print(matrices_multiplied)\n",
    "\n",
    "# Do an element-wise multiplication of tensor_of_ones with identity_tensor\n",
    "element_multiplication = tensor_of_ones * identity_tensor\n",
    "print(element_multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation by auto-differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(-3., requires_grad=True)\n",
    "y = torch.tensor(5., requires_grad=True)\n",
    "z = torch.tensor(-2., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Gradient of z is: tensor(2.)\n",
      "Gradient of y is: tensor(-2.)\n",
      "Gradient of x is: tensor(-2.)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "q = x + y\n",
    "f = q * z\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print(\"Gradient of z is: \" + str(z.grad)) \n",
    "print(\"Gradient of y is: \" + str(y.grad)) \n",
    "print(\"Gradient of x is: \" + str(x.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(6.), tensor(18.), tensor(0.), tensor(6.), tensor(0.), tensor(12.))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "a = torch.tensor(0.)\n",
    "b = torch.tensor(1.)\n",
    "\n",
    "\n",
    "w1 = torch.tensor(0., requires_grad=True)\n",
    "w2 = torch.tensor(1., requires_grad=True)\n",
    "w3 = torch.tensor(2., requires_grad=True)\n",
    "w4 = torch.tensor(3., requires_grad=True)\n",
    "w5 = torch.tensor(1., requires_grad=True)\n",
    "w6 = torch.tensor(2., requires_grad=True)\n",
    "\n",
    "c = a * w1 + b * w2\n",
    "d = a * w3 + b * w4\n",
    "e = c * w5 + d * w6\n",
    "l = (e - 4) ** 2\n",
    "\n",
    "l.backward()\n",
    "\n",
    "w5.grad, w6.grad, w1.grad, w2.grad, w3.grad, w4.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 6.],\n        [18.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.,  0.],\n        [ 6., 12.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    }
   ],
   "source": [
    "input_data = torch.tensor([[0., 1.]])\n",
    "w_h1 = torch.tensor([[0., 2.],\n",
    "                     [1., 3.]], requires_grad=True)\n",
    "w_h2 = torch.tensor([[1.],\n",
    "                     [2.]], requires_grad=True)\n",
    "\n",
    "h1 = torch.matmul(input_data, w_h1)\n",
    "p = torch.matmul(h1, w_h2)\n",
    "\n",
    "l = (p - 4) ** 2\n",
    "\n",
    "l.backward()\n",
    "w_h2.grad\n",
    "w_h1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Nerual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([340.5824, 281.8968, 303.5075, 288.3683])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "input_layer = torch.rand(10)\n",
    "\n",
    "w1 = torch.rand(10, 20) \n",
    "w2 = torch.rand(20, 20) \n",
    "w3 = torch.rand(20, 4)\n",
    "\n",
    "h1 = torch.matmul(input_layer, w1) \n",
    "h2 = torch.matmul(h1, w2)\n",
    "output_layer = torch.matmul(h2, w3) \n",
    "\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() \n",
    "        self.fc1 = nn.Linear(10, 20) \n",
    "        self.fc2 = nn.Linear(20, 20) \n",
    "        self.output = nn.Linear(20, 4)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "result = net(input_layer)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "#### Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "input_layer = torch.tensor([2., 1.])\n",
    "weight_1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]]) \n",
    "hidden_layer = torch.matmul(input_layer, weight_1) \n",
    "weight_2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]]) \n",
    "output_layer = torch.matmul(hidden_layer, weight_2) \n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication is a linear transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "input_layer = torch.tensor([2., 1.])\n",
    "weight_1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]]) \n",
    "weight_2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]]) \n",
    "weight = torch.matmul(weight_1, weight_2)\n",
    "output_layer = torch.matmul(input_layer, weight) \n",
    "print(output_layer)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([2., 0.], grad_fn=<ReluBackward0>)\n",
      "tensor([[2.0000, 0.0000],\n",
      "        [1.2000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "tensor_1 = torch.tensor([2., -4.], requires_grad=True)\n",
    "out = relu(tensor_1)\n",
    "out1 = out.sum()\n",
    "print(out)\n",
    "tensor_2 = torch.tensor([[2., -4.], [1.2, 0.]], requires_grad=True)\n",
    "out = relu(tensor_2)\n",
    "out2 = out.sum()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 0.])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    },
    {
     "data": {
      "text/plain": "tensor([[1., 0.],\n        [1., 0.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    }
   ],
   "source": [
    "out1.backward()\n",
    "out2.backward()\n",
    "tensor_1.grad\n",
    "tensor_2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[-0.9892, -1.3952,  0.0102,  0.6443]])\n",
      "tensor([[-0.9892, -1.3952,  0.0102,  0.6443]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "input_layer = torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]])\n",
    "weight_1 = torch.tensor([[-0.1094, -0.8285,  0.0416, -1.1222],\n",
    "                         [ 0.3327, -0.0461,  1.4473, -0.8070],\n",
    "                         [ 0.0681, -0.7058, -1.8017,  0.5857],\n",
    "                         [ 0.8764,  0.9618, -0.4505,  0.2888]])\n",
    "weight_2 = torch.tensor([[ 0.6856, -1.7650,  1.6375, -1.5759],\n",
    "                         [-0.1092, -0.1620,  0.1951, -0.1169],\n",
    "                         [-0.5120,  1.1997,  0.8483, -0.2476],\n",
    "                         [-0.3369,  0.5617, -0.6658,  0.2221]])\n",
    "weight_3 = torch.rand(4, 4)\n",
    "\n",
    "\n",
    "# 计算隐层输出\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
    "\n",
    "# 计算网络输出\n",
    "print(torch.matmul(hidden_2, weight_3))\n",
    "\n",
    "# 计算参数矩阵乘法\n",
    "weight_composed_1 = torch.matmul(weight_1, weight_2)\n",
    "weight = torch.matmul(weight_composed_1, weight_3)\n",
    "\n",
    "# 计算网络输出\n",
    "print(torch.matmul(input_layer, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0.3763, 0.0828, 0.4502, 0.5157]])\n",
      "tensor([[-1.4975, -2.0198, -1.1524, -0.6569]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 引入relu增加网络的非线性拟合能力\n",
    "hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\n",
    "hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\n",
    "print(torch.matmul(hidden_2_activated, weight_3))\n",
    "\n",
    "# 计算参数矩阵乘积\n",
    "weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n",
    "weight = relu(torch.matmul(weight_composed_1_activated, weight_3))\n",
    "\n",
    "# 计算网络输出\n",
    "print(torch.matmul(input_layer, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "logits = torch.tensor([[3.2, 5.1, -1.7]]) \n",
    "ground_truth = torch.tensor([0]) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, ground_truth) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "logits = torch.tensor([[10.2, 5.1, -1.7]]) \n",
    "loss = criterion(logits, ground_truth) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "logits = torch.tensor([[-10, 5.1, -1.7]]) \n",
    "loss = criterion(logits, ground_truth) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a dataset in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torchvision  # 数据集和预训练网络\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.48216, 0.44653),\n",
    "                                                     (0.24703, 0.24349, 0.26159))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Applications/GitHub/MachineLearning-tarin-kaikeba/task_5/data/cifar-10-python.tar.gz\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a3d4faa2bdc4c6daec05191b65e0146"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='/Applications/GitHub/MachineLearning-tarin-kaikeba/task_5/data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='/Applications/GitHub/MachineLearning-tarin-kaikeba/task_5/data', train=False, \n",
    "                                       download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, \n",
    "                                          shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, \n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting the dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "testloader.dataset\n",
    "trainloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "testloader.dataset.data.shape\n",
    "trainloader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "testloader.batch_size\n",
    "trainloader.sampler\n",
    "testloader.sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 500) \n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "for epoch in range(10): # 数据集的循环次数\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取输入\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "\n",
    "        # 重置优化器\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播 + 反向传播 + loss计算\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels) \n",
    "        # 梯度下降\n",
    "        loss.backward()\n",
    "        # 参数更行\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs, 1) \n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "* 使用Keras或PyTorch搭建全连接神经网络，完成在MNIST and CIFAR-10上的训练和评测\n",
    "* 优化网络结构和超参，尽量提高模型效果\n",
    "* ``目前我们还没有讲到在Pytorch中模型的验证方法，在后续的课程中我会给大家慢慢介绍。但是聪明的你们可以利用目前所学，自己建立一种验证机制吗``\n",
    "\n",
    "*到此，我们虽然已经有能力对具体的问题建模训练和预测了，但是可能效果并不会很好，因为我们后面还会给大家讲到网络的正则，以及更powerful的网络结构，在此之前，也请大家积极练习，夯实基础方法和网络原理，加油！*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cce60d86",
   "language": "python",
   "display_name": "PyCharm (untitled)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}